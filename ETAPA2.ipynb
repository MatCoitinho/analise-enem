{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16e2e79",
   "metadata": {},
   "source": [
    "## 1) Importações e Definição de Diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec0a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import zip_longest\n",
    "MICRODATA_FILES = {\n",
    "    2021: Path(\"microdados/enem_2021/DADOS/MICRODADOS_ENEM_2021.csv\"),\n",
    "    2022: Path(\"microdados/enem_2022/DADOS/MICRODADOS_ENEM_2022.csv\"),\n",
    "    2023: Path(\"microdados/enem_2023/DADOS/MICRODADOS_ENEM_2023.csv\"),\n",
    "}\n",
    "NA_VALUES = [\"\", \" \", \"NA\", \"N/A\", \"NULL\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abae4d6",
   "metadata": {},
   "source": [
    "## 2) Carregar microdados e concatenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2704dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados: (10799892, 77)\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for ano, p in MICRODATA_FILES.items():\n",
    "    if not p.exists():\n",
    "        print('Arquivo não encontrado:', p)\n",
    "        continue\n",
    "    else:\n",
    "        df = pd.read_csv(p, sep=';', decimal='.', encoding='iso-8859-1', dtype='string', na_values=NA_VALUES, low_memory=False)\n",
    "    df['ANO_REFERENCIA'] = ano\n",
    "    frames.append(df)\n",
    "if not frames:\n",
    "    raise RuntimeError('Nenhum arquivo carregado. Ajuste MICRODATA_FILES e rode novamente.')\n",
    "dados = pd.concat(frames, ignore_index=True, sort=False)\n",
    "print('Dados carregados:', dados.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1efcc5",
   "metadata": {},
   "source": [
    "## 3) Identificar colunas com Missing values (percentual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_pct = dados.isna().mean() * 100\n",
    "display(missing_pct[missing_pct>0].sort_values(ascending=False).to_frame('missing_pct').head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f5cf7",
   "metadata": {},
   "source": [
    "## 4) Tratamento para Missing Values\n",
    "Uma quantidade considerável de missing values está relacionado ao não comparecimento nas provas. Para eliminar essas colunas, será considerado apenas os registros onde o aluno possui presença em todas as provas.\n",
    "\n",
    "Além disso, todas as colunas que representam dados da escola do participante também possuem uma porcentagem alta de missing values, por conta disso, essas colunas serão desconsideradas.\n",
    "\n",
    "Também iremos desconsiderar grande parte das perguntas do questionário socioeconômico, manteremos apenas perguntas que julgamos ser dados que podem ser usados para encontrar padrões no dataset.\n",
    "\n",
    "Por fim, também iremos desconsiderar as colunas NU_INSCRICAO, TP_ANO_CONCLUIU, TP_ENSINO, CO_MUNICIPIO_PROVA, NO_MUNICIPIO_PROVA e também todas as colunas de Código do Tipo de Prova, que indicam qual cor de prova o participante realizou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5865ddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após filtrar presenças: (7261194, 77)\n"
     ]
    }
   ],
   "source": [
    "required_presence = ['TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT']\n",
    "dados_limpos = dados.copy()\n",
    "missing_presence = [c for c in required_presence if c not in dados_limpos.columns]\n",
    "if missing_presence:\n",
    "    print('Colunas de presença ausentes:', missing_presence)\n",
    "else:\n",
    "    presence_numeric = dados_limpos[required_presence].apply(pd.to_numeric, errors='coerce')\n",
    "    mask = presence_numeric.eq(1).all(axis=1)\n",
    "    dados_limpos = dados_limpos[mask].copy()\n",
    "    print('Após filtrar presenças:', dados_limpos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23730aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas removidas: ['CO_MUNICIPIO_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'NO_MUNICIPIO_ESC', 'CO_UF_ESC', 'SG_UF_ESC', 'TP_SIT_FUNC_ESC', 'TP_LOCALIZACAO_ESC']\n"
     ]
    }
   ],
   "source": [
    "drop_columns = [\n",
    "        'CO_MUNICIPIO_ESC',\n",
    "        'TP_DEPENDENCIA_ADM_ESC',\n",
    "        'NO_MUNICIPIO_ESC',\n",
    "        'CO_UF_ESC',\n",
    "        'SG_UF_ESC',\n",
    "        'TP_SIT_FUNC_ESC',\n",
    "        'TP_LOCALIZACAO_ESC',\n",
    "    ]\n",
    "cols_to_drop = [c for c in drop_columns if c in dados_limpos.columns]\n",
    "if cols_to_drop:\n",
    "    dados_limpos = dados_limpos.drop(columns=cols_to_drop)\n",
    "    print('Colunas removidas:', cols_to_drop)\n",
    "else:\n",
    "    print('Colunas escolares já ausentes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9663ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas Q0 removidas: 19\n"
     ]
    }
   ],
   "source": [
    "keep_q_cols = {'Q001', 'Q002', 'Q006', 'Q022', 'Q024', 'Q025'}\n",
    "q_cols_to_drop = [c for c in dados_limpos.columns if c.startswith('Q0') and c not in keep_q_cols]\n",
    "if q_cols_to_drop:\n",
    "    dados_limpos = dados_limpos.drop(columns=q_cols_to_drop)\n",
    "    print('Colunas Q0 removidas:', len(q_cols_to_drop))\n",
    "else:\n",
    "    print('Nenhuma coluna Q0 para remover.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92946b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas extras removidas: ['NU_INSCRICAO', 'TP_ANO_CONCLUIU', 'TP_ENSINO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA']\n",
      "Colunas CO_PROVA removidas: 4\n"
     ]
    }
   ],
   "source": [
    "extra_drop = ['NU_INSCRICAO', 'TP_ANO_CONCLUIU', 'TP_ENSINO', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA']\n",
    "extra_cols = [c for c in extra_drop if c in dados_limpos.columns]\n",
    "if extra_cols:\n",
    "    dados_limpos = dados_limpos.drop(columns=extra_cols)\n",
    "    print('Colunas extras removidas:', extra_cols)\n",
    "else:\n",
    "    print('Colunas extras já ausentes.')\n",
    "co_prova_cols = [c for c in dados_limpos.columns if c.startswith('CO_PROVA')]\n",
    "if co_prova_cols:\n",
    "    dados_limpos = dados_limpos.drop(columns=co_prova_cols)\n",
    "    print('Colunas CO_PROVA removidas:', len(co_prova_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cdf79f",
   "metadata": {},
   "source": [
    "Com essas limpezas realizadas, ao refazer a busca de missing_values, apenas resta poucas respostas as perguntas do questionário socioeconômico mantidas que não foram respondidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5029a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pct = dados_limpos.isna().mean() * 100\n",
    "display(missing_pct[missing_pct>0].sort_values(ascending=False).to_frame('missing_pct').head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54feedfd",
   "metadata": {},
   "source": [
    "Quantidade real de registros restantes com missing values em cada coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93563411",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7bdbe",
   "metadata": {},
   "source": [
    "Como sobrou apenas um registro com missing value, ele será desconsiderado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos[dados_limpos['Q006'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0ffd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.dropna(subset=['Q006'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37081545",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc849638",
   "metadata": {},
   "source": [
    "## 5) Enriquecimento\n",
    "Foi decidido que iremos excluir as colunas de gabarito e respostas, e criar uma nova coluna para marcar as questões acertadas e erradas. No caso, as colunas de gabarito e respostas estão em formato string no padrão: 'abdebcedf*.a' sendo asterisco a dupla marcação e o . como em branco. A ideia da nova coluna para substituir será de colocar uma string apenas de 0 e 1, indicando erro e acerto. Com isso, também será criado uma nova coluna, que indica a porcentagem de acertos em determinada área do conhecimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf05a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Áreas processadas: ['CN', 'CH', 'LC', 'MT']\n",
      "Colunas removidas: ['TX_GABARITO_CN', 'TX_RESPOSTAS_CN', 'TX_GABARITO_CH', 'TX_RESPOSTAS_CH', 'TX_GABARITO_LC', 'TX_RESPOSTAS_LC', 'TX_GABARITO_MT', 'TX_RESPOSTAS_MT']\n"
     ]
    }
   ],
   "source": [
    "def respostas_para_boolean(resposta, gabarito):\n",
    "    if not isinstance(resposta, str) or not isinstance(gabarito, str):\n",
    "        return np.nan\n",
    "    resp = resposta.upper()\n",
    "    gab = gabarito.upper()\n",
    "    bits = []\n",
    "    for r, g in zip_longest(resp, gab, fillvalue=None):\n",
    "        if r is None or g is None:\n",
    "            continue\n",
    "        if r in {'*', '.', ' '}:\n",
    "            bits.append('0')\n",
    "        elif r == g and g in {'A', 'B', 'C', 'D', 'E'}:\n",
    "            bits.append('1')\n",
    "        else:\n",
    "            bits.append('0')\n",
    "    return ''.join(bits) if bits else np.nan\n",
    "\n",
    "def boolean_para_pct(bits):\n",
    "    if not isinstance(bits, str) or not bits:\n",
    "        return np.nan\n",
    "    valid = [b for b in bits if b in {'0', '1'}]\n",
    "    if not valid:\n",
    "        return np.nan\n",
    "    return (valid.count('1') / len(valid)) * 100\n",
    "\n",
    "area_pairs = []\n",
    "for gab_col in [c for c in dados_limpos.columns if c.startswith('TX_GABARITO_')]:\n",
    "    area = gab_col.replace('TX_GABARITO_', '')\n",
    "    resp_col = f'TX_RESPOSTAS_{area}'\n",
    "    if resp_col in dados_limpos.columns:\n",
    "        area_pairs.append((area, gab_col, resp_col))\n",
    "\n",
    "if area_pairs:\n",
    "    print('Áreas processadas:', [area for area, _, _ in area_pairs])\n",
    "    for area, gab_col, resp_col in area_pairs:\n",
    "        acertos_col = f'TX_ACERTOS_{area}'\n",
    "        pct_col = f'PCT_ACERTO_{area}'\n",
    "        dados_limpos[acertos_col] = [\n",
    "            respostas_para_boolean(resp, gab)\n",
    "            for resp, gab in zip(dados_limpos[resp_col], dados_limpos[gab_col])\n",
    "        ]\n",
    "        dados_limpos[pct_col] = dados_limpos[acertos_col].apply(boolean_para_pct)\n",
    "    cols_to_drop = [col for _, gab_col, resp_col in area_pairs for col in (gab_col, resp_col)]\n",
    "    dados_limpos.drop(columns=cols_to_drop, inplace=True)\n",
    "    print('Colunas removidas:', cols_to_drop)\n",
    "else:\n",
    "    print('Nenhuma combinação de gabarito e respostas encontrada.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801dfd2a",
   "metadata": {},
   "source": [
    "Para facilitar a classificação de duas perguntas socioeconômicas, a Q022 e Q024, que são, respectivamente, de posse de celular e computador, iremos trocar os valores da resposta para apenas 0 e 1, 0 se não houver e 1 se houver 1 ou mais aparelhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90eba015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q022 convertida para binário.\n",
      "Q024 convertida para binário.\n",
      "Q025 convertida para binário.\n"
     ]
    }
   ],
   "source": [
    "for col in ['Q022', 'Q024', 'Q025']:\n",
    "    if col in dados_limpos.columns:\n",
    "        dados_limpos[col] = dados_limpos[col].str.upper().map({'A': 0, 'B': 1, 'C': 1, 'D': 1, 'E': 1})\n",
    "        print(f'{col} convertida para binário.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fcf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd438e60",
   "metadata": {},
   "source": [
    "## 6) Padronização de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7cf05ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7261193 entries, 1 to 10799890\n",
      "Data columns (total 42 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   NU_ANO             string \n",
      " 1   TP_FAIXA_ETARIA    string \n",
      " 2   TP_SEXO            string \n",
      " 3   TP_ESTADO_CIVIL    string \n",
      " 4   TP_COR_RACA        string \n",
      " 5   TP_NACIONALIDADE   string \n",
      " 6   TP_ST_CONCLUSAO    string \n",
      " 7   TP_ESCOLA          string \n",
      " 8   IN_TREINEIRO       string \n",
      " 9   CO_UF_PROVA        string \n",
      " 10  SG_UF_PROVA        string \n",
      " 11  TP_PRESENCA_CN     string \n",
      " 12  TP_PRESENCA_CH     string \n",
      " 13  TP_PRESENCA_LC     string \n",
      " 14  TP_PRESENCA_MT     string \n",
      " 15  NU_NOTA_CN         string \n",
      " 16  NU_NOTA_CH         string \n",
      " 17  NU_NOTA_LC         string \n",
      " 18  NU_NOTA_MT         string \n",
      " 19  TP_LINGUA          string \n",
      " 20  TP_STATUS_REDACAO  string \n",
      " 21  NU_NOTA_COMP1      string \n",
      " 22  NU_NOTA_COMP2      string \n",
      " 23  NU_NOTA_COMP3      string \n",
      " 24  NU_NOTA_COMP4      string \n",
      " 25  NU_NOTA_COMP5      string \n",
      " 26  NU_NOTA_REDACAO    string \n",
      " 27  Q001               string \n",
      " 28  Q002               string \n",
      " 29  Q006               string \n",
      " 30  Q022               int64  \n",
      " 31  Q024               int64  \n",
      " 32  Q025               int64  \n",
      " 33  ANO_REFERENCIA     int64  \n",
      " 34  TX_ACERTOS_CN      object \n",
      " 35  PCT_ACERTO_CN      float64\n",
      " 36  TX_ACERTOS_CH      object \n",
      " 37  PCT_ACERTO_CH      float64\n",
      " 38  TX_ACERTOS_LC      object \n",
      " 39  PCT_ACERTO_LC      float64\n",
      " 40  TX_ACERTOS_MT      object \n",
      " 41  PCT_ACERTO_MT      float64\n",
      "dtypes: float64(4), int64(4), object(4), string(30)\n",
      "memory usage: 2.3+ GB\n"
     ]
    }
   ],
   "source": [
    "dados_limpos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98b614e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos_cols = [c for c in dados_limpos.columns if c.startswith('TX_ACERTOS_')]\n",
    "for col in acertos_cols:\n",
    "    dados_limpos[col] = dados_limpos[col].astype('string').str.strip()\n",
    "\n",
    "string_cols = dados_limpos.select_dtypes(include='string').columns.tolist()\n",
    "if string_cols:\n",
    "    dados_limpos[string_cols] = dados_limpos[string_cols].apply(lambda s: s.str.strip())\n",
    "\n",
    "numeric_candidates = [\n",
    "    c for c in dados_limpos.columns\n",
    "    if c not in acertos_cols and dados_limpos[c].dtype == 'string'\n",
    "]\n",
    "numeric_converted = []\n",
    "for col in numeric_candidates:\n",
    "    coerced = pd.to_numeric(dados_limpos[col], errors='coerce')\n",
    "    non_convertible = (~dados_limpos[col].isna()) & coerced.isna()\n",
    "    if non_convertible.any() or coerced.dropna().empty:\n",
    "        continue\n",
    "    if (coerced.dropna() % 1 == 0).all():\n",
    "        dados_limpos[col] = coerced.astype('Int64')\n",
    "    else:\n",
    "        dados_limpos[col] = coerced.astype('float64').round(2)\n",
    "    numeric_converted.append(col)\n",
    "\n",
    "float_cols = dados_limpos.select_dtypes(include='float').columns.tolist()\n",
    "if float_cols:\n",
    "    dados_limpos[float_cols] = dados_limpos[float_cols].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28bc2bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7261193 entries, 1 to 10799890\n",
      "Data columns (total 42 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   NU_ANO             Int64  \n",
      " 1   TP_FAIXA_ETARIA    Int64  \n",
      " 2   TP_SEXO            string \n",
      " 3   TP_ESTADO_CIVIL    Int64  \n",
      " 4   TP_COR_RACA        Int64  \n",
      " 5   TP_NACIONALIDADE   Int64  \n",
      " 6   TP_ST_CONCLUSAO    Int64  \n",
      " 7   TP_ESCOLA          Int64  \n",
      " 8   IN_TREINEIRO       Int64  \n",
      " 9   CO_UF_PROVA        Int64  \n",
      " 10  SG_UF_PROVA        string \n",
      " 11  TP_PRESENCA_CN     Int64  \n",
      " 12  TP_PRESENCA_CH     Int64  \n",
      " 13  TP_PRESENCA_LC     Int64  \n",
      " 14  TP_PRESENCA_MT     Int64  \n",
      " 15  NU_NOTA_CN         float64\n",
      " 16  NU_NOTA_CH         float64\n",
      " 17  NU_NOTA_LC         float64\n",
      " 18  NU_NOTA_MT         float64\n",
      " 19  TP_LINGUA          Int64  \n",
      " 20  TP_STATUS_REDACAO  Int64  \n",
      " 21  NU_NOTA_COMP1      Int64  \n",
      " 22  NU_NOTA_COMP2      Int64  \n",
      " 23  NU_NOTA_COMP3      Int64  \n",
      " 24  NU_NOTA_COMP4      Int64  \n",
      " 25  NU_NOTA_COMP5      Int64  \n",
      " 26  NU_NOTA_REDACAO    Int64  \n",
      " 27  Q001               string \n",
      " 28  Q002               string \n",
      " 29  Q006               string \n",
      " 30  Q022               int64  \n",
      " 31  Q024               int64  \n",
      " 32  Q025               int64  \n",
      " 33  ANO_REFERENCIA     int64  \n",
      " 34  TX_ACERTOS_CN      string \n",
      " 35  PCT_ACERTO_CN      float64\n",
      " 36  TX_ACERTOS_CH      string \n",
      " 37  PCT_ACERTO_CH      float64\n",
      " 38  TX_ACERTOS_LC      string \n",
      " 39  PCT_ACERTO_LC      float64\n",
      " 40  TX_ACERTOS_MT      string \n",
      " 41  PCT_ACERTO_MT      float64\n",
      "dtypes: Int64(21), float64(8), int64(4), string(9)\n",
      "memory usage: 2.5 GB\n"
     ]
    }
   ],
   "source": [
    "dados_limpos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b3c43",
   "metadata": {},
   "source": [
    "## 7) Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_notas = [\n",
    "    \"NU_NOTA_CN\", \"NU_NOTA_CH\", \"NU_NOTA_LC\", \"NU_NOTA_MT\",\n",
    "    \"NU_NOTA_COMP1\", \"NU_NOTA_COMP2\", \"NU_NOTA_COMP3\",\n",
    "    \"NU_NOTA_COMP4\", \"NU_NOTA_COMP5\", \"NU_NOTA_REDACAO\"\n",
    "]\n",
    "\n",
    "colunas_pct = [\"PCT_ACERTO_CN\", \"PCT_ACERTO_CH\", \"PCT_ACERTO_LC\", \"PCT_ACERTO_MT\"]\n",
    "\n",
    "colunas_analise = colunas_notas + colunas_pct\n",
    "\n",
    "df = dados_limpos.copy()\n",
    "\n",
    "colunas_existentes = [c for c in colunas_analise if c in df.columns]\n",
    "\n",
    "def detectar_outliers_iqr(df, coluna):\n",
    "    Q1 = df[coluna].quantile(0.25)\n",
    "    Q3 = df[coluna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[coluna] < limite_inferior) | (df[coluna] > limite_superior)]\n",
    "    return outliers, limite_inferior, limite_superior\n",
    "\n",
    "resumo_outliers = []\n",
    "\n",
    "for coluna in colunas_existentes:\n",
    "    outliers, li, ls = detectar_outliers_iqr(df, coluna)\n",
    "    resumo_outliers.append({\n",
    "        \"Coluna\": coluna,\n",
    "        \"Qtd_Outliers\": len(outliers),\n",
    "        \"Limite_Inferior\": round(li, 2),\n",
    "        \"Limite_Superior\": round(ls, 2)\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(data=df, y=coluna, color=\"skyblue\")\n",
    "    plt.title(f\"Boxplot - {coluna}\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "resumo_df = pd.DataFrame(resumo_outliers)\n",
    "print(\"Resumo de Outliers por Coluna:\")\n",
    "display(resumo_df.sort_values(by=\"Qtd_Outliers\", ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
