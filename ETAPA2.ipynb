{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16e2e79",
   "metadata": {},
   "source": [
    "## 1) Importações e Definição de Diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import zip_longest\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "MICRODATA_FILES = {\n",
    "    2021: Path(\"microdados/enem_2021/DADOS/MICRODADOS_ENEM_2021.csv\"),\n",
    "    2022: Path(\"microdados/enem_2022/DADOS/MICRODADOS_ENEM_2022.csv\"),\n",
    "    2023: Path(\"microdados/enem_2023/DADOS/MICRODADOS_ENEM_2023.csv\"),\n",
    "}\n",
    "NA_VALUES = [\"\", \" \", \"NA\", \"N/A\", \"NULL\", \"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abae4d6",
   "metadata": {},
   "source": [
    "## 2) Carregar microdados e concatenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2704dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for ano, p in MICRODATA_FILES.items():\n",
    "    if not p.exists():\n",
    "        print('Arquivo não encontrado:', p)\n",
    "        continue\n",
    "    else:\n",
    "        df = pd.read_csv(p, sep=';', decimal='.', encoding='iso-8859-1', dtype='string', na_values=NA_VALUES, low_memory=False)\n",
    "    df['ANO_REFERENCIA'] = ano\n",
    "    frames.append(df)\n",
    "if not frames:\n",
    "    raise RuntimeError('Nenhum arquivo carregado. Ajuste MICRODATA_FILES e rode novamente.')\n",
    "dados = pd.concat(frames, ignore_index=True, sort=False)\n",
    "print('Dados carregados:', dados.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1efcc5",
   "metadata": {},
   "source": [
    "## 3) Identificar colunas com Missing values (percentual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_pct = dados.isna().mean() * 100\n",
    "display(missing_pct[missing_pct>0].sort_values(ascending=False).to_frame('missing_pct').head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f5cf7",
   "metadata": {},
   "source": [
    "## 4) Tratamento para Missing Values\n",
    "Uma quantidade considerável de missing values está relacionado ao não comparecimento nas provas. Para eliminar essas colunas, será considerado apenas os registros onde o aluno possui presença em todas as provas.\n",
    "\n",
    "Além disso, todas as colunas que representam dados da escola do participante também possuem uma porcentagem alta de missing values, por conta disso, essas colunas serão desconsideradas.\n",
    "\n",
    "Também iremos desconsiderar grande parte das perguntas do questionário socioeconômico, manteremos apenas perguntas que julgamos ser dados que podem ser usados para encontrar padrões no dataset.\n",
    "\n",
    "Por fim, também iremos desconsiderar as colunas NU_INSCRICAO, TP_ANO_CONCLUIU, TP_ENSINO, CO_MUNICIPIO_PROVA, NO_MUNICIPIO_PROVA e também todas as colunas de Código do Tipo de Prova, que indicam qual cor de prova o participante realizou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_presence = ['TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT']\n",
    "dados_limpos = dados.copy()\n",
    "missing_presence = [c for c in required_presence if c not in dados_limpos.columns]\n",
    "if missing_presence:\n",
    "    print('Colunas de presença ausentes:', missing_presence)\n",
    "else:\n",
    "    presence_numeric = dados_limpos[required_presence].apply(pd.to_numeric, errors='coerce')\n",
    "    mask = presence_numeric.eq(1).all(axis=1)\n",
    "    dados_limpos = dados_limpos[mask].copy()\n",
    "    print('Após filtrar presenças:', dados_limpos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23730aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "        'CO_MUNICIPIO_ESC',\n",
    "        'TP_DEPENDENCIA_ADM_ESC',\n",
    "        'NO_MUNICIPIO_ESC',\n",
    "        'CO_UF_ESC',\n",
    "        'SG_UF_ESC',\n",
    "        'TP_SIT_FUNC_ESC',\n",
    "        'TP_LOCALIZACAO_ESC',\n",
    "    ]\n",
    "cols_to_drop = [c for c in drop_columns if c in dados_limpos.columns]\n",
    "if cols_to_drop:\n",
    "    dados_limpos = dados_limpos.drop(columns=cols_to_drop)\n",
    "    print('Colunas removidas:', cols_to_drop)\n",
    "else:\n",
    "    print('Colunas escolares já ausentes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9663ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_q_cols = {'Q001', 'Q002', 'Q006', 'Q022', 'Q024', 'Q025'}\n",
    "q_cols_to_drop = [c for c in dados_limpos.columns if c.startswith('Q0') and c not in keep_q_cols]\n",
    "if q_cols_to_drop:\n",
    "    dados_limpos = dados_limpos.drop(columns=q_cols_to_drop)\n",
    "    print('Colunas Q0 removidas:', len(q_cols_to_drop))\n",
    "else:\n",
    "    print('Nenhuma coluna Q0 para remover.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92946b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_drop = ['NU_INSCRICAO', 'TP_ANO_CONCLUIU', 'TP_ENSINO']\n",
    "extra_cols = [c for c in extra_drop if c in dados_limpos.columns]\n",
    "if extra_cols:\n",
    "    dados_limpos = dados_limpos.drop(columns=extra_cols)\n",
    "    print('Colunas extras removidas:', extra_cols)\n",
    "else:\n",
    "    print('Colunas extras já ausentes.')\n",
    "co_prova_cols = [c for c in dados_limpos.columns if c.startswith('CO_PROVA')]\n",
    "if co_prova_cols:\n",
    "    dados_limpos = dados_limpos.drop(columns=co_prova_cols)\n",
    "    print('Colunas CO_PROVA removidas:', len(co_prova_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cdf79f",
   "metadata": {},
   "source": [
    "Com essas limpezas realizadas, ao refazer a busca de missing_values, apenas resta poucas respostas as perguntas do questionário socioeconômico mantidas que não foram respondidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5029a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pct = dados_limpos.isna().mean() * 100\n",
    "display(missing_pct[missing_pct>0].sort_values(ascending=False).to_frame('missing_pct').head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54feedfd",
   "metadata": {},
   "source": [
    "Quantidade real de registros restantes com missing values em cada coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93563411",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7bdbe",
   "metadata": {},
   "source": [
    "Como sobrou apenas um registro com missing value, ele será desconsiderado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos[dados_limpos['Q006'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ffd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.dropna(subset=['Q006'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37081545",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc849638",
   "metadata": {},
   "source": [
    "## 5) Enriquecimento\n",
    "Foi decidido que iremos excluir as colunas de gabarito e respostas, e criar uma nova coluna para marcar as questões acertadas e erradas. No caso, as colunas de gabarito e respostas estão em formato string no padrão: 'abdebcedf*.a' sendo asterisco a dupla marcação e o . como em branco. A ideia da nova coluna para substituir será de colocar uma string apenas de 0 e 1, indicando erro e acerto. Com isso, também será criado uma nova coluna, que indica a porcentagem de acertos em determinada área do conhecimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respostas_para_boolean(resposta, gabarito):\n",
    "    if not isinstance(resposta, str) or not isinstance(gabarito, str):\n",
    "        return np.nan\n",
    "    resp = resposta.upper()\n",
    "    gab = gabarito.upper()\n",
    "    bits = []\n",
    "    for r, g in zip_longest(resp, gab, fillvalue=None):\n",
    "        if r is None or g is None:\n",
    "            continue\n",
    "        if r in {'*', '.', ' '}:\n",
    "            bits.append('0')\n",
    "        elif r == g and g in {'A', 'B', 'C', 'D', 'E'}:\n",
    "            bits.append('1')\n",
    "        else:\n",
    "            bits.append('0')\n",
    "    return ''.join(bits) if bits else np.nan\n",
    "\n",
    "def boolean_para_pct(bits):\n",
    "    if not isinstance(bits, str) or not bits:\n",
    "        return np.nan\n",
    "    valid = [b for b in bits if b in {'0', '1'}]\n",
    "    if not valid:\n",
    "        return np.nan\n",
    "    return (valid.count('1') / len(valid)) * 100\n",
    "\n",
    "area_pairs = []\n",
    "for gab_col in [c for c in dados_limpos.columns if c.startswith('TX_GABARITO_')]:\n",
    "    area = gab_col.replace('TX_GABARITO_', '')\n",
    "    resp_col = f'TX_RESPOSTAS_{area}'\n",
    "    if resp_col in dados_limpos.columns:\n",
    "        area_pairs.append((area, gab_col, resp_col))\n",
    "\n",
    "if area_pairs:\n",
    "    print('Áreas processadas:', [area for area, _, _ in area_pairs])\n",
    "    for area, gab_col, resp_col in area_pairs:\n",
    "        acertos_col = f'TX_ACERTOS_{area}'\n",
    "        pct_col = f'PCT_ACERTO_{area}'\n",
    "        dados_limpos[acertos_col] = [\n",
    "            respostas_para_boolean(resp, gab)\n",
    "            for resp, gab in zip(dados_limpos[resp_col], dados_limpos[gab_col])\n",
    "        ]\n",
    "        dados_limpos[pct_col] = dados_limpos[acertos_col].apply(boolean_para_pct)\n",
    "    cols_to_drop = [col for _, gab_col, resp_col in area_pairs for col in (gab_col, resp_col)]\n",
    "    dados_limpos.drop(columns=cols_to_drop, inplace=True)\n",
    "    print('Colunas removidas:', cols_to_drop)\n",
    "else:\n",
    "    print('Nenhuma combinação de gabarito e respostas encontrada.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801dfd2a",
   "metadata": {},
   "source": [
    "Para facilitar a classificação de duas perguntas socioeconômicas, a Q022 e Q024, que são, respectivamente, de posse de celular e computador, iremos trocar os valores da resposta para apenas 0 e 1, 0 se não houver e 1 se houver 1 ou mais aparelhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eba015",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Q022', 'Q024', 'Q025']:\n",
    "    if col in dados_limpos.columns:\n",
    "        dados_limpos[col] = dados_limpos[col].str.upper().map({'A': 0, 'B': 1, 'C': 1, 'D': 1, 'E': 1})\n",
    "        print(f'{col} convertida para binário.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d11c835",
   "metadata": {},
   "source": [
    "Trazer os dados do PIB das cidades onde a prova foi realizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb078c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANO_PIB = \"2021\"\n",
    "TABELA_SIDRA = \"5938\"\n",
    "VARIAVEL_PIB = \"37\"\n",
    "\n",
    "url = f\"https://servicodados.ibge.gov.br/api/v3/agregados/{TABELA_SIDRA}/periodos/{ANO_PIB}/variaveis/{VARIAVEL_PIB}?localidades=N6[all]\"\n",
    "\n",
    "print(\"Consultando PIB municipal via API v3 do IBGE...\")\n",
    "r = requests.get(url, timeout=60)\n",
    "r.raise_for_status()\n",
    "\n",
    "data = r.json()\n",
    "\n",
    "records = []\n",
    "for loc in data[0][\"resultados\"][0][\"series\"]:\n",
    "    cod_mun = int(loc[\"localidade\"][\"id\"])\n",
    "    valor = loc[\"serie\"][ANO_PIB]\n",
    "    pib = float(valor.replace(\",\", \".\")) if valor not in (None, \"...\") else None\n",
    "    records.append({\"CO_MUNICIPIO_PROVA\": cod_mun, \"PIB_MUNICIPIO\": pib})\n",
    "\n",
    "df_pib = pd.DataFrame(records)\n",
    "\n",
    "dados_limpos[\"CO_MUNICIPIO_PROVA\"] = dados_limpos[\"CO_MUNICIPIO_PROVA\"].astype(int)\n",
    "df_pib[\"CO_MUNICIPIO_PROVA\"] = df_pib[\"CO_MUNICIPIO_PROVA\"].astype(int)\n",
    "\n",
    "dados_limpos = dados_limpos.merge(df_pib, on=\"CO_MUNICIPIO_PROVA\", how=\"left\")\n",
    "\n",
    "dados_limpos[[\"CO_MUNICIPIO_PROVA\", \"PIB_MUNICIPIO\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fcf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd438e60",
   "metadata": {},
   "source": [
    "## 6) Padronização de Dados\n",
    "Foi realizada a padronização dos tipos de dados do conjunto do ENEM, convertendo as variáveis categóricas (Q001, Q002, Q006 e TX_ACERTOS_*) para string e as demais colunas para valores numéricos. Além disso, os números decimais foram arredondados para duas casas decimais, garantindo consistência e melhor legibilidade dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b614e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_str = [\n",
    "    'TX_ACERTOS_CN', 'TX_ACERTOS_CH', 'TX_ACERTOS_LC', 'TX_ACERTOS_MT',\n",
    "    'Q001', 'Q002', 'Q006', 'TP_SEXO', 'SG_UF_PROVA', 'NO_MUNICIPIO_PROVA'\n",
    "]\n",
    "\n",
    "for col in cols_str:\n",
    "    if col in dados_limpos.columns:\n",
    "        dados_limpos[col] = dados_limpos[col].astype(str)\n",
    "\n",
    "cols_num = [col for col in dados_limpos.columns if col not in cols_str]\n",
    "\n",
    "for col in cols_num:\n",
    "    dados_limpos[col] = pd.to_numeric(dados_limpos[col], errors='coerce')\n",
    "\n",
    "for col in cols_num:\n",
    "    if pd.api.types.is_float_dtype(dados_limpos[col]):\n",
    "        dados_limpos[col] = dados_limpos[col].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_limpos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b3c43",
   "metadata": {},
   "source": [
    "## 7) Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_notas = [\n",
    "    \"NU_NOTA_CN\", \"NU_NOTA_CH\", \"NU_NOTA_LC\", \"NU_NOTA_MT\",\n",
    "    \"NU_NOTA_COMP1\", \"NU_NOTA_COMP2\", \"NU_NOTA_COMP3\",\n",
    "    \"NU_NOTA_COMP4\", \"NU_NOTA_COMP5\", \"NU_NOTA_REDACAO\"\n",
    "]\n",
    "\n",
    "colunas_pct = [\"PCT_ACERTO_CN\", \"PCT_ACERTO_CH\", \"PCT_ACERTO_LC\", \"PCT_ACERTO_MT\"]\n",
    "\n",
    "colunas_analise = colunas_notas + colunas_pct\n",
    "\n",
    "df = dados_limpos.copy()\n",
    "\n",
    "colunas_existentes = [c for c in colunas_analise if c in df.columns]\n",
    "\n",
    "def detectar_outliers_iqr(df, coluna):\n",
    "    Q1 = df[coluna].quantile(0.25)\n",
    "    Q3 = df[coluna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[coluna] < limite_inferior) | (df[coluna] > limite_superior)]\n",
    "    return outliers, limite_inferior, limite_superior\n",
    "\n",
    "resumo_outliers = []\n",
    "\n",
    "for coluna in colunas_existentes:\n",
    "    outliers, li, ls = detectar_outliers_iqr(df, coluna)\n",
    "    resumo_outliers.append({\n",
    "        \"Coluna\": coluna,\n",
    "        \"Qtd_Outliers\": len(outliers),\n",
    "        \"Limite_Inferior\": round(li, 2),\n",
    "        \"Limite_Superior\": round(ls, 2)\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(data=df, y=coluna, color=\"skyblue\")\n",
    "    plt.title(f\"Boxplot - {coluna}\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "resumo_df = pd.DataFrame(resumo_outliers)\n",
    "print(\"Resumo de Outliers por Coluna:\")\n",
    "display(resumo_df.sort_values(by=\"Qtd_Outliers\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f9a74",
   "metadata": {},
   "source": [
    "Todas as colunas de outliers se justificam pela natureza das colunas em si. Podem existir alunos com notas nas áreas de conhecimento e redação que se destacam das demais. O mesmo vale para porcentagem de acertos nas questões de cada área de conhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ad1e6",
   "metadata": {},
   "source": [
    "## 8) Exportação\n",
    "Exportação dos dados limpos para um csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850be932",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('dados_limpos.csv')\n",
    "dados_limpos.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f'Arquivo salvo em: {output_path.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8f27a",
   "metadata": {},
   "source": [
    "## 9) Visualizações para diagnóstico de qualidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f100ffd",
   "metadata": {},
   "source": [
    "### Porcentagem de missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797983c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_before = dados.isnull().mean() * 100\n",
    "missing_after = dados_limpos.isnull().mean() * 100\n",
    "\n",
    "df_missing = pd.DataFrame({\n",
    "    'Antes da Limpeza': missing_before,\n",
    "    'Depois da Limpeza': missing_after\n",
    "})\n",
    "\n",
    "df_missing = df_missing[(df_missing['Antes da Limpeza'] > 0) | (df_missing['Depois da Limpeza'] > 0)]\n",
    "\n",
    "df_missing = df_missing.reset_index().melt(id_vars='index', var_name='Situação', value_name='Percentual')\n",
    "df_missing.rename(columns={'index': 'Coluna'}, inplace=True)\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"Set2\", font_scale=1.1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.barplot(data=df_missing, x='Coluna', y='Percentual', hue='Situação')\n",
    "\n",
    "plt.title('Porcentagem de Dados Faltantes Antes e Depois da Limpeza')\n",
    "plt.xlabel('Coluna')\n",
    "plt.ylabel('Percentual de Dados Faltantes (%)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Situação')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf01b3",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e50d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_notas = [\n",
    "    \"NU_NOTA_CN\", \"NU_NOTA_CH\", \"NU_NOTA_LC\", \"NU_NOTA_MT\",\n",
    "    \"NU_NOTA_COMP1\", \"NU_NOTA_COMP2\", \"NU_NOTA_COMP3\",\n",
    "    \"NU_NOTA_COMP4\", \"NU_NOTA_COMP5\", \"NU_NOTA_REDACAO\"\n",
    "]\n",
    "\n",
    "colunas_pct = [\n",
    "    \"PCT_ACERTO_CN\", \"PCT_ACERTO_CH\", \"PCT_ACERTO_LC\", \"PCT_ACERTO_MT\"\n",
    "]\n",
    "\n",
    "for col in colunas_notas:\n",
    "    if col in dados.columns:\n",
    "        dados[col] = pd.to_numeric(dados[col], errors='coerce')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "sns.boxplot(data=dados[colunas_notas], ax=axes[0])\n",
    "axes[0].set_title(\"Distribuição Antes da Limpeza\")\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "colunas_apos = [col for col in colunas_notas + colunas_pct if col in dados_limpos.columns]\n",
    "sns.boxplot(data=dados_limpos[colunas_apos], ax=axes[1])\n",
    "axes[1].set_title(\"Distribuição Após Limpeza\")\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
